{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Native\n",
				"import re\n",
				"import sys\n",
				"import time\n",
				"\n",
				"# Third party\n",
				"import pandas as pd\n",
				"from splinter import Browser\n",
				"\n",
				"# Custom\n",
				"sys.path.append(\"..\")\n",
				"from linkedIn_cred import linkedIn_email, linkedIn_password\n",
				"from scripts.company_objects import daugherty, slalom, _1904labs, worldWideTechnology"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"companies = [daugherty, slalom, _1904labs, worldWideTechnology]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
				"browser = Browser(\"chrome\", **executable_path, headless=False)\n",
				"browser.driver.set_window_size(\n",
				"    1600, 900\n",
				")  # Has to be wide enough to prevent messenger from covering filter buttons"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def log_on_to_linkedIn():\n",
				"    browser.visit(companies[0].linkedin)\n",
				"    button = browser.links.find_by_partial_href(\"https://www.linkedin.com/login?\")\n",
				"    button.click()\n",
				"    browser.fill(\"session_key\", linkedIn_email)\n",
				"    browser.fill(\"session_password\", linkedIn_password)\n",
				"    button = browser.find_by_value(\"Sign in\")\n",
				"    button.click()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": true
			},
			"outputs": [],
			"source": [
				"def scrape_profile_metadata(company):\n",
				"    url = company.linkedin\n",
				"    browser.visit(url)\n",
				"    html = browser.html\n",
				"    data = {}\n",
				"\n",
				"    followers = re.search(r\"[\\d,]+ followers\", html, re.DOTALL).group()\n",
				"    followers = re.sub(\"[^\\d]\", \"\", followers)  # returns only digits\n",
				"    followers = int(followers)\n",
				"\n",
				"    employees_on_linkedin = re.search(r\"[\\d,]+ employees\", html, re.DOTALL).group()\n",
				"    employees_on_linkedin = re.sub(\n",
				"        \"[^\\d]\", \"\", employees_on_linkedin\n",
				"    )  # returns only digits\n",
				"    employees_on_linkedin = int(employees_on_linkedin)\n",
				"\n",
				"    print(\n",
				"        f\"{company.name} has {followers} followers and {employees_on_linkedin} employees on LinkedIn.\"\n",
				"    )\n",
				"\n",
				"    data[\"name\"] = [company.name]\n",
				"    data[\"followers\"] = [followers]\n",
				"    data[\"employees_on_linkedin\"] = [employees_on_linkedin]\n",
				"\n",
				"    profile_metadata_df = pd.DataFrame(data=data)\n",
				"    profile_metadata_df.to_csv(f\"../data/{company.name}_profile_metadata.csv\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def scrape_profile_posts_by_most_recent():\n",
				"    button = browser.find_by_css(\"div[class='sort-dropdown mt2 ember-view']\")\n",
				"    button.click()\n",
				"    button = browser.find_by_text(\"Recent\")\n",
				"    button.click()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def scroll_down_until_all_posts_are_loaded():\n",
				"    number_posts_before_scroll = len(\n",
				"        browser.find_by_css(\"div[class='occludable-update ember-view']\")\n",
				"    )\n",
				"\n",
				"    while number_posts_before_scroll > 1:\n",
				"        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
				"        number_posts_after_scroll = len(\n",
				"            browser.find_by_css(\"div[class='occludable-update ember-view']\")\n",
				"        )\n",
				"\n",
				"        if number_posts_before_scroll == number_posts_after_scroll:\n",
				"            timer = time.time()\n",
				"            thirty_seconds_elapsed = timer + 30\n",
				"\n",
				"            while time.time() < thirty_seconds_elapsed:\n",
				"                browser.execute_script(\n",
				"                    \"window.scrollTo(0, document.body.scrollHeight);\"\n",
				"                )\n",
				"                number_posts_after_scroll = len(\n",
				"                    browser.find_by_css(\"div[class='occludable-update ember-view']\")\n",
				"                )\n",
				"\n",
				"            if number_posts_before_scroll == number_posts_after_scroll:\n",
				"                print(\"finished\")\n",
				"                break\n",
				"        else:\n",
				"            number_posts_before_scroll = len(\n",
				"                browser.find_by_css(\"div[class='occludable-update ember-view']\")\n",
				"            )\n",
				"\n",
				"    print(f\"Number of posts {number_posts_before_scroll}\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def scrape_company_posts(id):\n",
				"    posts = browser.find_by_css(\"div[class='occludable-update ember-view']\")\n",
				"\n",
				"    data = {\"content\": [], \"like_count\": [], \"comment_count\": [], \"date\": []}\n",
				"\n",
				"    for post in posts:\n",
				"        post = post.text\n",
				"\n",
				"        try:\n",
				"            date = re.search(r\"^(\\w+ •\\n|\\w+ ago\\n)\", post, re.MULTILINE).group()\n",
				"            date = re.sub(\"\\n\", \"\", date)\n",
				"        except Exception as e:\n",
				"            print(f\"no date: {e}\")\n",
				"            date = \"\"\n",
				"\n",
				"        try:\n",
				"            like_count = re.search(r\"^[\\d]+$\", post, re.MULTILINE).group()\n",
				"            like_count = int(like_count)\n",
				"        except Exception as e:\n",
				"            print(f\"no like count: {e}\")\n",
				"            like_count = 0\n",
				"\n",
				"        try:\n",
				"            # Content always follows the time the post was published and precedes the like count.\n",
				"            contentRegex = re.compile(\n",
				"                f\"( •\\n| ago\\n).*?^({like_count})$\", re.MULTILINE | re.DOTALL\n",
				"            )\n",
				"            content = re.search(contentRegex, post).group()\n",
				"            content = re.sub(\n",
				"                r\"( •\\n| ago\\n)\", \"\", content, re.MULTILINE | re.DOTALL\n",
				"            )  # Gets rid of the leading timestamp\n",
				"            content = content[\n",
				"                : -len(str(like_count))\n",
				"            ]  # Gets rid of the trailing like count\n",
				"        except Exception as e:\n",
				"            print(f\"no content: {e}\")\n",
				"            content = \"\"\n",
				"\n",
				"        try:\n",
				"            comment_area = re.search(r\"^[\\d]+ comment(s)?$\", post, re.MULTILINE).group()\n",
				"            comment_count = re.sub(r\"[^\\d]\", \"\", comment_area)  # returns only digits\n",
				"            comment_count = int(comment_count)\n",
				"        except Exception as e:\n",
				"            print(f\"no comment count: {e}\")\n",
				"            comment_count = 0\n",
				"\n",
				"        print(f\"\\n\\nlikes: {like_count}\")\n",
				"        print(f\"comments: {comment_count}\")\n",
				"        print(f\"content: {content}\")\n",
				"\n",
				"        data[\"content\"].append(content)\n",
				"        data[\"like_count\"].append(like_count)\n",
				"        data[\"comment_count\"].append(comment_count)\n",
				"        data[\"date\"].append(date)\n",
				"\n",
				"    company_posts_df = pd.DataFrame(data)\n",
				"    company_posts_df.to_csv(f\"../data/{companies[id].name}_company_posts.csv\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": true
			},
			"outputs": [],
			"source": [
				"log_on_to_linkedIn()\n",
				"\n",
				"for id in range(len(companies)):\n",
				"    scrape_profile_metadata(companies[id])\n",
				"    browser.visit(companies[id].linkedin)\n",
				"    scrape_profile_posts_by_most_recent()\n",
				"    scroll_down_until_all_posts_are_loaded()\n",
				"    scrape_company_posts(id)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.8.5"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
